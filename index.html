<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hyungwoon Lee</title>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="./index.css">
</head>
<body>
    <div class="scroll-progress"></div>
    
    <nav>
        <div class="nav-container">
            <span title="This is Frenny! A mascot character I drew in 2021 for one of my first ever web development projects... and it just stuck around as a profile logo since then."><img src="assets/frenny.jpg" alt="Frenny" class="nav-logo"></span>
            <div class="nav-links">
                <a href="#about">About Me!</a>
                <a href="#research">Research Interests</a>
                <a href="#nonresearch">Non-Research Interests</a>
                <a href="#projects">Projects</a>
                <a href="#publications">Publications</a>
            </div>
        </div>
    </nav>

    <div class="container">
        <header>
            <div class="header-content">
                <h1>Hyungwoon Lee</h1>
                <p class="subtitle">HCI, AI, ML & Psychology Researcher | National University of Singapore (NUS)</p>
                <div class="contact-links">
                    <a href="mailto:leehw@ahlab.org" title="My Email - leehw@ahlab.org">
                        <i class="fas fa-envelope"></i>
                    </a>
                    <a href="https://github.com/lhw-1" target="_blank" title="My GitHub - @lhw-1">
                        <i class="fab fa-github"></i>
                    </a>
                </div>
            </div>
            <span title="This picture was taken in Stockholm, Sweden during my visit in late 2025 after UbiComp '25 was held in Espoo, Finland. Credits to Prof. Rick Glassey at KTH for helping me take this photograph :D"><img src="assets/hyungwoon.PNG" alt="Profile Picture" class="profile-picture"></span>
        </header>

        <section id="about">
            <h2>About Me!</h2>
            <p class="bio">
                Heyo! My name is <strong>Hyungwoon</strong>, though people just call me <strong>Hyung</strong>, usually :)
            </p>
            <p class="bio">
                My undergraduate studies were at the <a href="https://www.nus.edu.sg/" target="_blank">National University of Singapore (NUS)</a>, in <strong>Computer Science</strong> and <strong>Psychology</strong>, with an emphasis on <strong>machine learning and AI</strong>, as well as <strong>clinical and cognitive psychology</strong>. 
            </p>
            <p class="bio">
                I have previously been a research assistant at the <a href="https://ahlab.org" target="_blank">Augmented Human Lab</a> @ NUS, advised by Prof. <a href="https://www.comp.nus.edu.sg/cs/people/suranga/" target="_blank">Suranga Nanayakkara</a>, where I worked on <strong>affective computing</strong> and <strong>assistive augmentation</strong> projects. I have also worked with the <a href="https://www.keanjhsu.com" target="_blank">Clinical Translational Sciences Lab</a> @ NUS under Prof. <a href="https://fass.nus.edu.sg/psy/people/kean-hsu/" target="_blank">Kean Hsu</a>, where I assisted with various behavioral task programming, eye-tracking configurations, and helping with writing research protocols. I have also been heavily involved with <em>CS1101S: Programming Methodology</em>, taught by Prof. <a href="https://www.comp.nus.edu.sg/cs/people/henz/" target="_blank">Martin Henz</a>. During my candidature, I was active as both a senior undergraduate tutor and a senior developer as part of the leadership team for <a href="https://sourceacademy.nus.edu.sg/" target="_blank">Source Academy</a>, a web-based learning platform developed and maintained by NUS students for CS1101S.
            </p>
            <p class="bio">
                I am currently working as a research engineer at the <a href="https://ahlab.org/people/hyung-woon-lee/" target="_blank">Augmented Human Lab</a>. My research work focuses on the development of <strong>context-aware, multimodal cognitive augmentation systems</strong> that makes use of physiological biosensing and biofeedback in order to augment <strong>learning</strong> and <strong>memory</strong>, particularly in the domain of education. My background in machine learning and AI, psychology, and Human-Computer Interaction (HCI) provides me with a unique perspective and skillset to build <strong>Human-centred AI systems</strong> that align with theories drawn from cognitive sciences, psychology, and interaction design.
            </p>
        </section>

        <section id="research">
            <h2>Research Interests</h2>

            <div class="research-item">
                <button class="accordion-button">HCI and Cognitive Augmentation</button>
                <div class="accordion-content">
                    <p class="item-description-top">
                        Working with Prof. Suranga's AH Lab has been a blessing on my research journey - I was able to work with an interdisciplinary group of people, with experts from various domains such as information systems, interaction design, assistive technology, virtual reality, sensors and haptics, signal processing, machine learning, affective psychology, drone systems, communications and new media, UI/UX design, embedded systems, education pedagogy, clinical psychology... It has been, and continues to be, a great environment for new research ideas to be generated and ideated upon. My love for bridging fields together to generate interdisciplinary insights have so far thrived within the field of HCI, and I suspect that this will be the case for some time. 
                    </p>
                    <p class="item-description">
                        In particular, the HCI paradigm of <strong>augmentation technology</strong> has inspired me quite a bit. The idea of designing and developing technology that can assist, enhance, or amplify human capabilities has been the core drive behind technological progress in history, and I am happy to contribute towards augmentation technology that addresses human cognitive capabilities - especially in terms of learning and memory. What I want to work on in the future is, by combining my technical skills with my theoretical knowledge, build impactful and lasting systems that can easily be integrated into our daily lives while extending our cognitive mind and capabilities.
                    </p>
                </div>
            </div>

            <div class="research-item">
                <button class="accordion-button">Machine Learning and AI</button>
                <div class="accordion-content">
                    <p class="item-description-top">
                        I was always interested in the idea of "learning" from the perspective of a learner and an educator. However, when I started my undergraduate studies in NUS, I was exposed early to machine learning and AI as a field, which was when I realized the potential of looking at "learning" from a mathematical, statistical perspective as well. Many of my earlier research projects (which would later spark my love for research) made use of machine learning and AI, and over time, I realized I like thinking about the problem formulation aspect of machine learning and AI; for instance, during my <a href="#projects">student program classification project</a> with Prof. Martin Henz, the most exciting part was formulating the student program into a representation and selecting the appropriate machine learning model and architecture, such that the different output categories of student program would align with what we hypothesised as different kinds of thinking processes that the students go through when programming.
                    </p>
                    <p class="item-description">
                        Having worked with a diverse range of ML and AI techniques such as regression models, tree-based models and SVMs, deep learning for computer vision (CV) and natural language processing (NLP), reinforcement learning (RL), self-supervised learning (SSL), as well as encoders and transformer architectures (and of course Large Language Models (LLMs)), I now have a better intuition for selecting and constructing the appropriate model architectures for given problems. What I would like to do is to apply this intuition towards building <strong>context-aware multimodal AI</strong> pipelines that can be incorporated into cognitive augmentation systems.
                    </p>
                </div>
            </div>

            <div class="research-item">
                <button class="accordion-button">Cognitive Sciences, Psychology, and Education</button>
                <div class="accordion-content">
                    <p class="item-description-top">
                        When I first entered university, my early career aspirations were actually in education and teaching - and I got into research after finding out that you'd likely need a Ph.D. to become a lecturer. What I didn't know was that I would end up enjoying research and completely shift my career directions! I still enjoy teaching quite a bit, and I have served as an undergraduate tutor since my 2nd year in NUS, until graduation. CS1101S in particular was a large part of that enjoyment, having taught it in 4 separate semesters as an avenger (our codename for undergraduate tutor) and later a reflection tutor, a position usually reserved for graduate students.
                    </p>
                    <p class="item-description">
                        In my 2nd year, I converted my psychology minor (which was initially taken out of pure interest) into a double major, and started looking into clinical psychology specifically. However, after working with Prof. Kean Hsu in his CTS lab, which focused heavily on the impact of cognitive processes and biases on mental health, I realized that what really interested me was that cognitive aspect of psychology. When Prof. Suranga Nanayakkara formed his <a href="https://chill.nus.edu.sg/" target="_blank">Centre for Holistic Inquiry into Lifelong Learning (CHILL)</a>, I started working with the centre on learning-related projects such as <a href="#projects">iLEMS</a> and my <a href="#projects">final year project on acute cognitive stress detection</a>. Over time, I have concretized my interest in <strong>cognitive sciences and psychology</strong>, with an emphasis towards <strong>learning, memory, and mental models</strong> - and incorporating this knowledge into building impactful systems that align with the theory.
                    </p>
                </div>
            </div>

            <div class="research-item">
                <button class="accordion-button">Biosensing and Signal Processing</button>
                <div class="accordion-content">
                    <p class="item-description-top">
                        Signal processing was not my initial focus, but it was always something close to heart by way of music. I had dabbled in digital compositions since secondary school - and I only started looking into it as part of my research interests when I had to work with human biosignal data. Some of my early projects in the AH Lab were on voice acoustics, which introduced me to signal processing as a discipline. However, I credit CS4347: Sound and Music Computing course taught by Prof. <a href="https://www.comp.nus.edu.sg/cs/people/wangye/" target="_blank">Wang Ye</a> as the catalyst that really got me into signal processing, with his intuitive explanations on concepts such as signal decomposition or chord recognition. 
                    </p>
                    <p class="item-description">
                        Many of my projects have involved signal processing on sensor data; I have worked with sensors such as electroencephalography (EEG) for brain waves, photoplethysmogram (PPG) for blood volume pulse (BVP) which can infer heart rate variability (HRV) and blood oxygen saturation (SpO2), electrodermal activity (EDA) sensors for skin conductance, temperature sensors, and eye trackers. I have also worked with voice acoustics, respiratory rate, facial expressions & gestures, and other behavioral data (e.g. keyboard and mouse use). With (varying degrees of) experience in these signals and sensors, I would really like to make use of this knowledge in building the sensing and biofeedback mechanisms for cognitive augmentation systems.
                    </p>
                </div>
            </div>

        </section>

        <section id="nonresearch">
            <h2>Non-Research Interests</h2>

            <div class="research-item">
                <button class="accordion-button">Music and other Interests</button>
                <div class="accordion-content">
                    <p class="item-description-top">
                        My interest in music was sparked by video games - to be more specific, nintendo games that I played when I was young. When I first came to Singapore, I barely knew English (I commonly joke to my friends that I only knew five things: “yes”, “no”, “hello”, “goodbye”, “I love apples”. “I love apples” was one of those sentences that you get taught early on in Korean primary schools back then, for no real reason other than its simplicity). What fascinated me was how the music seemed to tell a story of its own, changing and evolving with different environments within the game. In secondary school, I started formally studying music as a subject - and I also took up bagpipes for my extra-curricular activity (a rare chance to learn a rare instrument). Since then, I have delved into digital music composition (initially using a pirated version of FL Studio 12, now with a full licensed version of FL Studio), live performances (I play both piano and bagpipes), and even did my IB extended essay on music - comparing Tchaikovsky's incidental music for <em>Hamlet</em> with Shostakovich's film music for <em>Hamlet</em>. I've also continued as a competitive bagpiper; I started in secondary school in 2013, and I have since been involved with the bagpiping scene. I am currently part of the Singapore Pipe Band Association Exco (for logistics & event organization), and recently have been part of Singapore's Grade 4A Lion City Pipe Band.
                    </p>
                    <p class="item-description">
                        Throughout the years, video game music remains one of my lasting hobbies. I love to analyse and enjoy the interplay of narrative and music, and the distinct yet diverse styles brought out by composers from different cultures for different video game genres. Someday, I aim to start a blog about video game music... someday.
                    </p>
                    <p class="item-description">
                        Apart from music and video games, I have other hobbies (that might not yet warrant full paragraphs) like origami, digital art, storywriting, cooking, films and cinematography, self-study of history, mythology and philosophy, etc. I partake in each of these every now and then, but all of these diverse experiences do contribute towards my generalized knowledge base and gives me experiences that I can build on (especially history, mythology, and philosophy - these provide wonderful basis for how to reason about real world issues and challenges, and sometimes even complements research directions and interests).
                    </p>
                </div>
            </div>

        </section>

        <section id="projects">
            <h2>Selected Projects</h2>
            <div class="project-item">
                <a href="projects/project-1.html" class="project-link">
                    <img src="assets/project-1.png" alt="Affect Recognition Project" class="project-image">
                </a>
                <div class="project-content">
                    <a href="projects/project-1.html" class="project-title-link">
                        <div class="item-title">Affect Recognition Project</div>
                    </a>
                    <div class="item-meta">Role: Research Engineer @ AH Lab | Duration: Nov 2024 - Ongoing</div>
                    <p class="item-description">
                        Project in collaboration with an industry partner. This project aims to build affect recognition model with state-of-the-Arts AI architecture, with the aim of integrating the model into wrist-worn / HMD wearable devices for affect-aware recommendation systems. (We have a <a href="#publications">workshop paper for NeurIPS '25</a> presented this year!)
                    </p>
                </div>
            </div>
            <div class="project-item">
                <a href="projects/project-2.html" class="project-link">
                    <img src="assets/project-2.png" alt="ProctorX" class="project-image">
                </a>
                <div class="project-content">
                    <a href="projects/project-2.html" class="project-title-link">
                        <div class="item-title">ProctorX</div>
                    </a>
                    <div class="item-meta">Role: Research Engineer @ CHILL | Duration: Sep 2024 - Jul 2025</div>
                    <p class="item-description">
                        Project in collaboration with NUS Centre for Teaching, Learning and Technology (CTLT). We built an AI-driven platform that can detect and flag the use of prohibited applications during open internet examinations. Video recordings and keyboard/mouse data are used by the platform to estimate the likelihood of prohibited applications being used - a surprisingly non-trivial task!
                    </p>
                </div>
            </div>
            <div class="project-item">
                <a href="projects/project-3.html" class="project-link">
                    <img src="assets/project-3.jpg" alt="Acute Cognitive Stress Detection" class="project-image">
                </a>
                <div class="project-content">
                    <a href="projects/project-3.html" class="project-title-link">
                        <div class="item-title">Acute Cognitive Stress Detection</div>
                    </a>
                    <div class="item-meta">Role: Final Year Student (4th Year) @ NUS | Duration: Aug 2024 - Apr 2025</div>
                    <p class="item-description">
                        This student research project focused on detection of acute cognitive stress that arises when students are working on mentally demanding tasks, especially when recalling information under pressure. Multimodal machine learning techniques were used alongside collected biosignal data (e.g. HRV, EDA, Temp) to build a multimodal stress classification model. [Report available upon request]
                    </p>
                </div>
            </div>
            <div class="project-item">
                <a href="projects/project-4.html" class="project-link">
                    <img src="assets/project-4.jpg" alt="iLEMS" class="project-image">
                </a>
                <div class="project-content">
                    <a href="projects/project-4.html" class="project-title-link">
                        <div class="item-title">Integrated Learning and Management System (iLEMS)</div>
                    </a>
                    <div class="item-meta">Role: Research Engineer @ CHILL | Duration: Jul 2024 - Jun 2025</div>
                    <p class="item-description">
                        This project was initiated under <a href="https://chill.nus.edu.sg/about/" target="_blank">CHILL @ NUS</a>. The iLEMS system is a web-based platform that integrates both course metadata and student behavioral and cognitive state data collected during course time to analyze and present the learning and engagement levels of students over time, allowing for instructors to have a more holistic view of the classroom. The platform is still a work in progress under CHILL.
                    </p>
                </div>
            </div>
            <div class="project-item">
                <a href="projects/project-5.html" class="project-link">
                    <img src="assets/project-5.png" alt="Emplity" class="project-image">
                </a>
                <div class="project-content">
                    <a href="projects/project-5.html" class="project-title-link">
                        <div class="item-title">Emplity</div>
                    </a>
                    <div class="item-meta">Role: Chief Research Officer / Co-founder | Duration: Nov 2023 - Ongoing</div>
                    <p class="item-description">
                        Emplity is my startup; we build AI-driven applications for mental health professionals in-training, and we are currently undergoing trials with institutes of higher learning and universities. If this sounds interesting to you as a potential collaborator / client, feel free to reach out!
                    </p>
                </div>
            </div>
            <div class="project-item">
                <a href="projects/project-6.html" class="project-link">
                    <img src="assets/project-6.png" alt="Student Program Classification" class="project-image">
                </a>
                <div class="project-content">
                    <a href="projects/project-6.html" class="project-title-link">
                        <div class="item-title">Student Program Classification</div>
                    </a>
                    <div class="item-meta">Role: Undergraduate Researcher (3rd Year) @ NUS | Duration: Jan 2023 - Dec 2023</div>
                    <p class="item-description">
                        This student research project focused on classifying student programs through low-level program traces extracted from abstract syntax trees (AST). Both standard machine learning models and LLMs were used to cluster programs based on these traces, with significant results. [Report available upon request]
                    </p>
                </div>
            </div>
            <div class="project-item">
                <a href="projects/project-7.html" class="project-link">
                    <img src="assets/project-7.png" alt="MarkBind" class="project-image">
                </a>
                <div class="project-content">
                    <a href="projects/project-7.html" class="project-title-link">
                        <div class="item-title">MarkBind</div>
                    </a>
                    <div class="item-meta">Role: Senior Developer @ NUS | Duration: Jul 2022 - Jun 2025</div>
                    <p class="item-description">
                        <a href="https://markbind.org/" target="_blank">MarkBind</a> is a command-line tool that can help to generate dynamic websites from simple markdown text. Built and maintained by students of National University of Singapore (NUS). I began work on it as a junior developer in my 3rd year, and continued to work as a senior developer until graduation.
                    </p>
                </div>
            </div>
            <div class="project-item">
                <a href="projects/project-8.html" class="project-link">
                    <img src="assets/project-8.jpg" alt="Robot Guide Dog" class="project-image">
                </a>
                <div class="project-content">
                    <a href="projects/project-8.html" class="project-title-link">
                        <div class="item-title">Robot Guide Dog</div>
                    </a>
                    <div class="item-meta">Role: Research Engineer Intern @ NUS AI Lab | Duration: May 2022 - Jul 2023</div>
                    <p class="item-description">
                        This was part of an ongoing <a href="https://www.ccsgp.comp.nus.edu.sg/robotic-dog-intern" target="_blank">research project</a> to build a navigation algorithm for a robotic guide dog in unseen environments, for the purpose of guiding visually impaired used. This project specifically focused on unseen navigation and stairs climbing.
                    </p>
                </div>
            </div>
            <div class="project-item">
                <a href="projects/project-9.html" class="project-link">
                    <img src="assets/project-9.jpg" alt="Source Academy" class="project-image">
                </a>
                <div class="project-content">
                    <a href="projects/project-9.html" class="project-title-link">
                        <div class="item-title">Source Academy</div>
                    </a>
                    <div class="item-meta">Role: Senior Developer @ NUS | Duration: Jul 2021 - Jun 2025</div>
                    <p class="item-description">
                        <a href="https://sourceacademy.nus.edu.sg/" target="_blank">Source Academy</a> is a web-based platform for interactive learning, designed around the Structure and Interpretation of Computer Programs (SICP) textbook, and used for the CS1101S: Programming Methodology I course. Built and maintained by students of National University of Singapore (NUS). I began work on it as a junior developer in my 2nd year, and continued to work as a senior developer until graduation.
                    </p>
                </div>
            </div>
        </section>

        <section id="publications">
            <h2>Publications</h2>

            <div class="publication-item">
                <div class="item-title">Don't Sleep on Sleep Data: Influence of Sleep Physiological Signals on Stress Detection.</div>
                <div class="item-meta"> Soundarya Ramesh, Takahiro Masuda, <strong>Lee Hyung Woon</strong>, Yongquan Hu, Suranga Chandima Nanayakkara. <strong>NeurIPS TS4H Workshop 2025.</strong></div>
                <button class="accordion-button">Abstract</button>
                <div class="accordion-content">
                    <p class="item-description-top">
                        Stress is a critical determinant of both short-term well-being and long-term health.  While wearable sensors have enabled continuous monitoring of stress through physiological signals, existing approaches that rely only on <em>current physiology</em> have shown limited success. Prior work suggests that the <em>previous night's sleep</em> is predictive of stress, yet current methods typically use only <em>coarse sleep summaries</em> (e.g., duration, resting heart rate). In this paper, we argue that <em>fine-grained sleep physiological data</em> can provide richer insights for stress detection. We collect a month-long smartwatch dataset comprising both day-time and night-time physiological signals, including detailed sleep-derived features, and train two models -- XGBoost and a custom multi-modal neural network. Our results provide initial evidence that incorporating fine-grained sleep features significantly improves stress detection, opening up several promising directions for future research.
                    </p>
                </div>
            </div>
        </section>

        <footer>
            <p>© 2025 - Hyungwoon Lee. Last updated: 1 Nov 2025</p>
        </footer>
    </div>

    <!-- GSAP Library -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.5/gsap.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/3.12.5/ScrollTrigger.min.js"></script>

    <script>
        // Initialize GSAP
        gsap.registerPlugin(ScrollTrigger);

        // Scroll progress bar
        gsap.to('.scroll-progress', {
            width: '100%',
            ease: 'none',
            scrollTrigger: {
                trigger: 'body',
                start: 'top top',
                end: 'bottom bottom',
                scrub: 0.3
            }
        });

        // Accordion functionality with animation
        const accordionButtons = document.querySelectorAll('.accordion-button');
        
        accordionButtons.forEach(button => {
            button.addEventListener('click', function() {
                const wasActive = this.classList.contains('active');
                
                // Close all other accordions
                accordionButtons.forEach(btn => {
                    if (btn !== this && btn.classList.contains('active')) {
                        btn.classList.remove('active');
                        const content = btn.nextElementSibling;
                        gsap.to(content, {
                            maxHeight: 0,
                            duration: 0.3,
                            ease: 'power2.inOut'
                        });
                    }
                });

                // Toggle current accordion
                this.classList.toggle('active');
                const content = this.nextElementSibling;
                
                if (!wasActive) {
                    gsap.to(content, {
                        maxHeight: content.scrollHeight,
                        duration: 0.4,
                        ease: 'power2.out'
                    });
                } else {
                    gsap.to(content, {
                        maxHeight: 0,
                        duration: 0.3,
                        ease: 'power2.inOut'
                    });
                }
            });
        });

        // Smooth scroll for navigation links with proper offset
        document.querySelectorAll('a[href^="#"]').forEach(anchor => {
            anchor.addEventListener('click', function (e) {
                e.preventDefault();
                const targetId = this.getAttribute('href');
                
                if (targetId === '#') return;
                
                const target = document.querySelector(targetId);
                if (target) {
                    const targetPosition = target.getBoundingClientRect().top + window.pageYOffset;
                    const offsetPosition = targetPosition - 90; // Account for fixed navbar height + some padding

                    window.scrollTo({
                        top: offsetPosition,
                        behavior: 'smooth'
                    });
                }
            });
        });
    </script>
</body>
</html>